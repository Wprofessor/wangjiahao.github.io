<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="icon" type="image/x-icon" href="images/wangjiahao.jpg" />
<title>Jiahao Wang (ç‹ä½³è±ª)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Jiahao Wang (ç‹ä½³è±ª) </h1>
</div>
<table class="imgtable"><tr>
<!-- ç¬¬ä¸€åˆ— -->
<td><a href="https://wangjiahao.github.io/"><img src="images/wangjiahao.jpg" alt="alt text" width="135px" /></a>&nbsp;</td>
<!-- ç¬¬äºŒåˆ— -->
<td align="left">
<p>æˆ‘ç›®å‰åœ¨<a href="https://www.xidian.edu.cn/">è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦</a><a href="https://sai.xidian.edu.cn/index.htm">äººå·¥æ™ºèƒ½å­¦é™¢</a>æ”»è¯»åšå£«å­¦ä½ï¼Œå¸ˆä»<a href="https://web.xidian.edu.cn/lchjiao/"><b>ç„¦ææˆé™¢å£«</b></a>å›¢é˜Ÿ<a href="https://web.xidian.edu.cn/fliu/"><b>åˆ˜èŠ³æ•™æˆ</b></a>ã€‚åœ¨å­¦æœŸé—´ï¼Œå›´ç»•å¤šæ¨¡æ€ä¿¡æ¯æå–ä»¥åŠå…³è”å»ºæ¨¡ç§‘å­¦é—®é¢˜å¼€å±•ç ”ç©¶ï¼Œä¸»è¦å†…å®¹åŒ…æ‹¬å¤šæ¨¡æ€èåˆï¼Œè§†è§‰è·Ÿè¸ªä»¥åŠé¥æ„Ÿå›¾åƒè§£è¯‘ç­‰ç ”ç©¶ã€‚ç›¸å…³æˆæœå·²åœ¨AAAIã€ACM MMã€Information Fusionã€TMMã€TCSVTã€TGRSç­‰å›½å†…å¤–æƒå¨ä¼šè®®å’ŒæœŸåˆŠä¸­å‘è¡¨ã€‚
<p>æˆ‘çš„ç ”ç©¶å…´è¶£ä¸»è¦åŒ…æ‹¬ğŸ˜ğŸ˜ğŸ˜: <br />
âœ”ï¸ <b>å¤šæ¨¡æ€èåˆ (Multimodal fusion)</b><br />
âœ”ï¸ <b>è§†è§‰è·Ÿè¸ª (Visual Tracking) </b><br />  
âœ”ï¸ <b>é¥æ„Ÿå›¾åƒè§£è¯‘ (Remote sensing image interpretation) </b><br /> 
</td>
<!-- ç¬¬ä¸‰åˆ— -->
<td align="left" class="contact-info">
  <ul><li><a href="jh_wang1024@163.com">ğŸ“§  [E-mail]</a></li></ul>
  <ul><li><a href="https://scholar.google.com/citations?user=PxzOUskAAAAJ&hl=zh-CN">ğŸ“ [Google Scholar]</a></li></ul>
  <!-- <ul><li><a href="https://github.com/qizhuang-qz">ğŸ“¥ [GitHub]</a></li></ul> -->
  <ul><li><a href="https://orcid.org/my-orcid?orcid=0000-0002-0375-9253">ğŸ†” [ORCID]</a></li></ul>
  <ul><li><a href="EnHome.html">ğŸ“‘ [English Page]</a></li></ul>
</td>
</tr></table>

<h2>Educational Background</h2> 
<ul>
<li><p>Sep. 2022 - Present: School of Artificial Intelligence, Xidian University, Ph.D. candidate</p></li>
<li><p>Sep. 2021 - Jul. 2022: School of Artificial Intelligence, Xidian University, Master's degree</p></li>
<li><p>Sep. 2017 - Jul. 2021: School of Big Data, North University of China, Bachelor's degree </p></li>
</ul>

<h2>å­¦æœ¯è®ºæ–‡</h2>
  <h4>2025</h4>
    <ul><li><p><a href="xxxxxxxxx">FA3T: Feature-Aware Adversarial Attacks for Multi-modal Tracking</a> <br />
    <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu, Xinyi Wang <br />
    <i>The 33rd ACM International Conference on Multimedia, (<b>ACM MM 2025</b>), 2025. </i> <br /> 
    <span class="special">[CCF Aç±» ä¼šè®®]</span> <br /> 
    </p></li></ul>

    <ul><li><p><a href="xxxxxxxxx">Imagining Vision From Language for Few-Shot Class-Incremental Learning</a> <br />
    Shuo Li, Xingchen Liu, Fang Liu, Licheng Jiao, <b>Jiahao Wang</b>, Xinyan Huang, Yanbiao Ma, Puhua Chen, Lingling Li, Xu Liu, Xuejian Gou <br />
    <i>The 33rd ACM International Conference on Multimedia, (<b>ACM MM 2025</b>), 2025. </i> <br /> 
    <span class="special">[CCF Aç±» ä¼šè®®]</span> <br /> 
    </p></li></ul>

     <ul><li><p><a href="xxxxxxxxx">Adaptive Visual Prompting for Efficient Satellite Video Tracking</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Yanbiao Ma, Lingling Li, Puhua Chen, Xu Liu, Mengjia Wang <br />
    <i> IEEE Transactions on Multimedia (<b>TMM</b>), 2025. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 9.7]</span> <br /> 
    </p></li></ul>

    <ul><li><p><a href="xxxxxxxxx">Adaptive Multi-modal Visual Tracking with Dynamic Semantic Prompts</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu, Wenping Ma, Xinyi Wang <br />
    <i> IEEE Transactions on Multimedia (<b>TMM</b>), 2025. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 9.7]</span> <br /> 
    </p></li></ul>

     <ul><li><p><a href="xxxxxxxxx"> VLPA-CLIP: Video Language Prompting and Adapting CLIP for efficient video action recognition</a> <br />
     Hao Wang, Fang Liu, Licheng Jiao, <b>Jiahao Wang</b>, Shuo Li, Lingling Li, Puhua Chen, Xu Liu, Wenping Ma <br />
    <i>  Pattern Recognition (<b>PR</b>), 2025. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 7.6]</span> <br /> 
    </p></li></ul>

    <ul><li><p><a href="xxxxxxxxx">Remote Sensing Video Tracking: Current Status, Challenges and Future</a> <br />
    Fang Liu, <b>Jiahao Wang</b>, Licheng Jiao, Jie Zhang,  Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu, Wenping Ma, Shuang Wang, Shuyuan Yang, Xiangrong  Zhang, Yaoyang  Du, Qianyue  Bao, Long Sun, Biao Hou <br />
    <i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>), 2025. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢äºŒåŒº, 5.3]</span> <br /> 
    </p></li></ul>

     <ul><li><p><a href="xxxxxxxxx">Change Knowledge-Guided Vision-Language Remote Sensing Change Detection</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu, Wenping Ma <br />
    <i> IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2025. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 8.6]</span> <br /> 
    </p></li></ul>
  
  
  <h4>2024</h4>
    <ul><li><p><a href="xxxxxxxxx">Visual and Language Collaborative Learning for RGBT Object Tracking</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Yingjia Gao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu <br />
    <i>  IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 11.1]</span> <br /> 
    </p></li></ul>

    <ul><li><p><a href="xxxxxxxxx"> Multi-modal visual tracking based on textual generation</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu <br />
    <i>   Information Fusion (<b> Information Fusion</b>), 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 15.5]</span> <br /> 
    </p></li></ul>

    <ul><li><p><a href="xxxxxxxxx"> Satellite Video Object Tracking based on Location Prompts</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Yingjia Gao, Hao Wang, Lingling Li, Puhua Chen, Xu Liu and Shuo Li <br />
    <i>  IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>), 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 11.1]</span> <br /> 
    </p></li></ul>

    <ul><li><p><a href="xxxxxxxxx"> Text generation and multi-modal knowledge transfer for few-shot object detection</a> <br />
     Yaoyang Du, Fang Liu, Licheng Jiao, Shuo Li, Zehua Hao, Pengfang Li,  <b>Jiahao Wang</b>, Hao Wang, Xu Liu <br />
    <i>  Pattern Recognition (<b>PR</b>), 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 7.6]</span> <br /> 
    </p></li></ul>


    <ul><li><p><a href="xxxxxxxxx">ViLT-CLIP: Video and Language Tuning CLIP with Multimodal Prompt Learning and Scenario-guided Optimization</a> <br />
    Hao Wang, Fang Liu, Licheng Jiao, <b>Jiahao Wang</b>, Zehua Hao, Shuo Li, Lingling Li, Puhua Chen and Xu Liu <br />
    <i> Proceedings of the AAAI Conference on Artificial Intelligence, (<b>AAAI 2024</b>), 2024. </i> <br /> 
    <span class="special">[CCF Aç±» ä¼šè®®]</span> <br /> 
    </p></li></ul>

  <h4>2023</h4>
    <ul><li><p><a href="xxxxxxxxx">SSCFNet: A Spatial-spectral Cross Fusion Network for Remote Sensing Change Detection</a> <br />
    <b>Jiahao Wang</b>, Fang Liu, Licheng Jiao, Hao Wang, Hua Yang, Xu Liu, Lingling Li and Puhua Chen<br />
    <i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>), 2023. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢äºŒåŒº, 5.3]</span> <br /> 
    </p></li></ul>

   <ul><li><p><a href="xxxxxxxxx">SDCDNet: A Semi-Dual Change Detection Network Framework with Super-Weak Lable for Remote Sensing Image</a> <br />
     <b>Jiahao Wang</b>, Fang Liu, Hao Wang, Xu Liu, Licheng Jiao, Hua Yang, Lingling Li and Puhua Chen <br />
    <i> IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>), 2023. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒºTOP, 8.6, ESIé«˜è¢«å¼•]</span> <br /> 
    </p></li></ul>



<h2>è£èª‰å¥–åŠ±</h2>
<ul>
<li><p>ECCVï¼ŒICCVï¼ŒCVPR Workshopç«èµ›å‰ä¸‰å8æ¬¡(2021ï¼Œ2022) </p></li>
<li><p>è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦ä¸€ç­‰å­¦ä¸šå¥–å­¦é‡‘ (2021ï¼Œ2022ï¼Œ2023) </p></li>
<li><p>è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦ç ”ç©¶ç”Ÿåˆ›æ–°åŸºé‡‘ (2024ï¼Œä¸»æŒ) </p></li>
<li><p>åšå£«ç”Ÿå›½å®¶å¥–å­¦é‡‘ (2024) </p></li>
<li><p>è…¾è®¯ç‰¹ç­‰å¥–å­¦é‡‘ (2024) </p></li>
</ul>  




<h2>å­¦æœ¯æœåŠ¡</h2>
<ul>
  Reviewer: NeurIPS, ICLR, CVPR, ICCV, MM, AAAI; TIP, TNNLS, TCSVT, TMM, TGRS, Neurocomputing and others.
  
  
</ul>


<div id="footer">
<div id="footer-text">
<br>Page generated 2025-07-17, by <a href="https://wangjiahao.github.io/">Jiahao Wang</a>.
</div>
</div>
</div>
</body>
</html>
